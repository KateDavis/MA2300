\documentclass[nohyper,justified]{tufte-handout}
\usepackage{mathtools}
%%\usepackage{marginnote}
%%\usepackage[top=1in, bottom=1in, outer=5.5in, inner=1in, heightrounded, marginparwidth=1in, marginparsep=1in]{geometry}
\usepackage{enumerate}
%% mess with the fonts
%%\usepackage{fontspec}
%%\defaultfontfeatures{Ligatures=TeX} % To support LaTeX quoting style
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
% For package xtable
\usepackage{booktabs}  % Nice toprules and bottomrules
\heavyrulewidth=1.5pt  % Change the default to heavier lines
\usepackage{longtable} 
%%\usepackage{tabularx}  % To control the width of the table

% this should make caption font bold.
%%\usepackage{xstring}
%%\usepackage{etoolbox}

%%\usepackage{url}

%% xetex only \usepackage{breakurl}
\usepackage{float} % for fig.pos='H'
%%\usepackage{wrapfig}
%%\usepackage{tikz}


\usepackage{colortbl,xcolor}
\makeatletter
% Paragraph indentation and separation for normal text
\renewcommand{\@tufte@reset@par}{%
  \setlength{\RaggedRightParindent}{0pc}%
  \setlength{\JustifyingParindent}{0pc}%
  \setlength{\parindent}{0pc}%
  \setlength{\parskip}{3pt}%
}
\@tufte@reset@par

% Paragraph indentation and separation for marginal text
\renewcommand{\@tufte@margin@par}{%
  \setlength{\RaggedRightParindent}{0pc}%
  \setlength{\JustifyingParindent}{0pc}%
  \setlength{\parindent}{0pc}%
  \setlength{\parskip}{2pt}%
}
\makeatother
\makeatletter
\title{Descriptive Statistics -- Associations}
\author{Kate Davis}
\makeatother

\newcommand{\dev}[1] {Dev_{\bar{#1}}}
\begin{document}
<<setup, include=FALSE, cache=FALSE,echo=FALSE>>=
library(knitr)
options(formatR.arrow=TRUE,width=50)
opts_chunk$set(fig.path='figure/graphics-', cache.path='cache/graphics-', fig.align='center', dev='pdf', fig.width=5, fig.height=5,  cache=FALSE,comment="",message=FALSE,echo=FALSE,warnings=FALSE,errors=FALSE)
knit_hooks$set(crop=hook_pdfcrop)
## ---- latex-functions ---- 
lcurrency<-function(incur) {
  #  gsub("$","\\\\$",currfmt(incur))
  currfmt(incur)
}
rpercent<-function(inval){
  percent(ceil(inval*100)/100)
}
lpercent<-function(inval) {
  gsub("%","\\\\%",percent(inval))
  #  percent(inval)
}
ltext<-function(inval) {
  xval=gsub("%","\\\\%",percent(inval))
  xval=gsub("&","\\\\&",percent(inval))
}
ldate<-function(indate){
  gsub(" 0"," ",format(indate,"%B %d, %Y"))
}
lmname<-function(indate){
  format(indate,"%B %Y")
}
ltable<-function(t,...){
  ltable=xtable(t,latex.environments='width=1.2\\textwidth,center',...)
}
ltableprint<-function(t,...){
  print( t, floating=TRUE, booktabs=TRUE, table.placement='h!',...)
}
g_legend<-function(a.gplot){
  tmp <- ggplot_gtable(ggplot_build(a.gplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)}


@

<<data,include=FALSE,cache=FALSE,echo=FALSE>>=
require(plyr)
require(reshape2)
require(xtable)
require(ggplot2)
require(ggthemes)
require(scales)
data(USArrests)
dsn <- USArrests
obsname="Assault"
obsname=c("Assault","Murder","UrbanPop")
obstext=c("Assault Arrests\nper 100,000 population","Murder Arrests\nper 100,000 population","Proportion Urban Population")
cc=c("Observation","Assault","Murder","UrbanPoP")
ofmt="%4.1f"
#ofmt="%d"
Answers=TRUE
#dsn$Candies=with(dsn,Red+Green+Blue+Orange+Yellow+Brown)
Nobs=nrow(dsn)
dsn$Observation=(1:Nobs)
hsum=as.matrix(sapply(dsn[,obsname],sum))
fivestat=as.data.frame(sapply(dsn[obsname],summary))
hmin=as.matrix(fivestat[1,])
hmax=as.matrix(fivestat[6,])
hrange=hmax-hmin
hmean=as.matrix(fivestat[4,])
dsn$DeviationX=dsn[,obsname[1]]-hmean[1]
dsn$DeviationY=dsn[,obsname[2]]-hmean[2]
dsn$DeviationZ=dsn[,obsname[3]]-hmean[3]
dsn$DeviationXSq=with(dsn,DeviationX^2)
dsn$DeviationYSq=with(dsn,DeviationY^2)
dsn$DeviationZSq=with(dsn,DeviationZ^2)
dsn$DeviationXY=with(dsn,DeviationX*DeviationY)
dsn$DeviationXZ=with(dsn,DeviationX*DeviationZ)
dsn$DeviationYZ=with(dsn,DeviationZ*DeviationY)
dsn$Obs=row.names(dsn)
#orgdata$DeviationSign[orgdata$Deviation<=0]="Negative"
sumDevxy=sum(dsn$DeviationXY)
sumDevxz=sum(dsn$DeviationXZ)
sumDevyz=sum(dsn$DeviationYZ)
covxy=sumDevxy/Nobs
covxz=sumDevxz/Nobs
covyz=sumDevyz/Nobs
dsn$devxysign=ifelse(sign(dsn$DeviationXY)==-1,"blue","yellow")
dsn$devxzsign=ifelse(sign(dsn$DeviationXZ)==-1,"blue","yellow")
dsn$devyzsign=ifelse(sign(dsn$DeviationYZ)==-1,"blue","yellow")
sumDevx=sum(dsn$DeviationXSq)
variancex=sumDevx/Nobs
stddevx=variancex^0.5
sumDevy=sum(dsn$DeviationYSq)
variancey=sumDevy/Nobs
stddevy=variancey^0.5
sumDevz=sum(dsn$DeviationZSq)
variancez=sumDevz/Nobs
stddevz=variancez^0.5
fivestat[7,]=c(sumDevx,sumDevy,sumDevz)
fivestat[8,]=c(variancex,variancey,variancez)
fivestat[9,]=c(stddevx,stddevy,stddevz)
fsr=row.names(fivestat)
fsr[7]="Sum Sq Deviation"
fsr[8]="Variance"
fsr[9]="Standard Deviation"
row.names(fivestat)=fsr
orgdata=dsn #[order(dsn[,obsname]),]
@

\maketitle
\section{Introduction to Associations}
We now consider the statistical associations between data. A data set can contain multiple data points per observation, and understaning how those data are associated within the observation is a key goal of descriptive and inferential statistical analysis. Examples of data sets are observations as patients, with data points as vital signs, or observations as states or counties and data points as crime statistics. 

Some associations that are often examined are statistics including covariance, correlations, and contingencies, and visualizations such as scatterplots and mosaic plots.

\section{US Arrest Statistics by Crime and State}
This data set contains statistics, in arrests per 100,000 residents for assault ($X$) and murder ($Y$) in each of the 50 states in 1973, along with the percent of population living in urban areas ($Z$).


<<basic-stats,comment="",results='asis'>>=
print(xtable(fivestat,digits=c(0,1,2,1),caption="Summary Statistics for US Arrests in 1973 "))
@
\newpage
\section{Scatterplots}
A \textbf{Scatterplot} of any two of the three variables shows the relationship on the same observation, in this case, State. 
<<scatterplotsxz,echo=FALSE,comment='',fig.cap="A scatterplot of Assault Arrests vs. Proportion Urban Population does not show a relationship",fig.env="marginfigure">>=
scp=ggplot(dsn,aes(y=Assault,x=UrbanPop,color=devxzsign))+geom_point()+
  scale_x_continuous(name=obstext[3])+
  scale_y_continuous(name=obstext[1])+
  geom_hline(yintercept=hmean[1],color="green")+
  geom_vline(xintercept=hmean[3],color="green")+
  theme(axis.text = element_text(size=1),legend.position="none")
print(scp)
@
<<scatterplotsyz,echo=FALSE,comment='',fig.cap="A scatterplot of Murder Arrests vs. Proportion Urban Population does not show a relationship",fig.env="marginfigure">>=
scp=ggplot(dsn,aes(x=Murder,y=UrbanPop,color=devyzsign))+geom_point()+
  scale_x_continuous(name=obstext[2])+
  scale_y_continuous(name=obstext[3])+
  geom_hline(yintercept=hmean[3],color="green")+
  geom_vline(xintercept=hmean[2],color="green")+
  theme(axis.text = element_text(size=1),legend.position="none")
print(scp)
@
<<scatterplotsxy,echo=FALSE,comment='',fig.cap="A scatterplot of Assault vs. Murder Arrests shows a possible linear relationship">>=
scp=ggplot(dsn,aes(y=Assault,x=Murder,color=devxysign))+geom_point()+
  scale_x_continuous(name=obstext[2])+
  scale_y_continuous(name=obstext[1])+
  geom_hline(yintercept=hmean[1],color="green")+
  geom_vline(xintercept=hmean[2],color="green")+
  theme(axis.text = element_text(size=1),legend.position="none")
print(scp)
@
\section{Covariance}
We would like to quantify the linear relationship between each of the variables. The \textbf{Covariance}, a measure of strength of the association between any two variables $X$ and $Y$, denoted $Cov(X,Y)$ is calculated by first multiplying the deviations from their means, $\dev{x}$ and $\dev{y}$, then summing over all observations and dividing by $N$, the number of observations. This is very similar to the population variance calculation, and the variance can be thought of as the covariance of a variable with itself ie. $Var(X)=Cov(X,X)$. 
\begin{equation*}
Cov(X,Y)=\frac{\Sigma_{i=1}^{N} Dev_{\bar{x}}Dev_{\bar{y}}}{N}
\end{equation*}
The Covariance of Assault Arrests with Murder Arrests is \Sexpr{covxy} "Assault Arrests x Murder Arrests". These units make very little sense. We cannot compare covariances among variables in a data set if the units are different.


<<covariance-table-1,echo=FALSE,include=TRUE,results='asis'>>=
maxlin=30
dcols=c("Obs",obsname,"DeviationXY","DeviationXZ","DeviationYZ")
dnames=c("Observation",obsname,"$\\dev{xy}$","${\\dev{xz}}$","${\\dev{xz}}$")
tdata=orgdata[1:maxlin,dcols]
names(tdata)=dnames
dtable=xtable(tdata,caption = "Covariances, Part 1")
rws <- seq(1, (nrow(tdata)-1), by = 2)
col <- rep("\\rowcolor[gray]{0.95}", length(rws))
#align(dtable) <- "|ccr|c|c|"
tt=capture.output(print(dtable,include.rownames=F, booktabs = TRUE, add.to.row = list(pos = as.list(rws), command = col),sanitize.text.function=function(x){x}))
cat(tt, sep = "\n")

@

\newpage
<<covariance-table-2,echo=FALSE,include=TRUE,results='asis'>>=
dcols=c("Obs",obsname,"DeviationXY","DeviationXZ","DeviationYZ")
dnames=c("Observation",obsname,"$\\dev{xy}$","${\\dev{xz}}$","${\\dev{xz}}$")
tdata=orgdata[(maxlin+1):nrow(orgdata),dcols]
names(tdata)=dnames
dtable=xtable(tdata[,],caption = "Covariances, Part 2")
rws <- seq(1, (nrow(tdata)-1), by = 2)
col <- rep("\\rowcolor[gray]{0.95}", length(rws))
#align(dtable) <- "|ccr|c|c|"
tt=capture.output(print(dtable,include.rownames=F, booktabs = TRUE, add.to.row = list(pos = as.list(rws), command = col),sanitize.text.function=function(x){x}))
#tt[headrow+1]=paste0("Obs & ",obsname," & $Dev_{\bar{x}}$ & $Dev_{\bar{x}}^2$ \\\\")
endrow=which(tt=="\\end{tabular}")
ltt=length(tt)
saveend=tt[endrow:ltt]
xfmt=sprintf("Total & %s & %s & %s & %s & %s & %s \\\\ ",ofmt,ofmt,ofmt,ofmt,ofmt,ofmt)
  tt[endrow]=sprintf(xfmt,hsum[1],hsum[2],hsum[3],sumDevxy,sumDevxz,sumDevyz)
xfmt=sprintf("\\rowcolor[gray]{0.95}Total/N & %s & %s & %s & %s & %s & %s \\\\ ",ofmt,ofmt,ofmt,ofmt,ofmt,ofmt)
 tt[endrow+1]=sprintf(xfmt,hmean[1],hmean[2],hmean[3],sumDevxy/Nobs,sumDevxz/Nobs,sumDevyz/Nobs)
  tt[endrow+2]=" & $\\bar{x}$ & $\\bar{y}$ & $\\bar{z}$ & $Cov(X,Y)$ & $Cov(X,Z)$ & $Cov(Y,Z)$   \\\\"
tt[(endrow+3):(endrow+3+length(saveend)-1)]=saveend
cat(tt, sep = "\n")

@
\newpage
\section{Linear Correlation}

A standardized Covariance is the \textbf{Linear Correlation}, calculated by dividing each Covariance by the Standard Deviations of each of the variables:

\begin{equation*}
Corr(X,Y)=\frac{Cov(Y,X)}{(StdDev(X)StdDev(Y))}
\end{equation*}

The Correlation of Assault Arrests with Murder Arrests is \Sexpr{covxy/(stddevx*stddevy)} with no units, so the correlations of multiple pairs of variables can be compared.

Correlations are always between $-1$ and $1$, and are a quantification of the linear relationship between two variables. A correlation of zero means that there is linear relationship between two variables, although there may be a non-linear relationship. A correlation of $1$ or $-1$ is indicates a perfect positive or negative linear relationship. $Corr(X,X)=1$ always.

\textbf{Correlation does not imply Causation!} Even if two variables have a high or perfect correlation, there is not necessarily causation. Causation means X depends on Y or Y depends on X. 

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}
\begin{figure}
{\centering \includegraphics[width=\maxwidth]{Correlation_types-Language-neutral.png} 
}
\caption[Correlation Types]{Examples of Correlation }\label{fig:correlationtypes}
\end{figure}
\textcircled{1} $Corr(X,Y)=0$ No Correlation \\
\textcircled{2} $Corr(X,Y)=0$ No Linear Correlation \\
\textcircled{3} $Corr(X,Y) approaching +1$ Positive Linear Correlation \\
\textcircled{4} $Corr(X,Y) approaching -1$ Negative Linear Correlation\\
\end{knitrout}

The Squared value of the correlation, \Sexpr{lpercent((covxy/(stddevx*stddevy))^2)}  is a measure of the "shared variance" of two variable, and the complement \Sexpr{lpercent(1-((covxy/(stddevx*stddevy)))^2)} is the proportion of variance not explained by the association.
\newpage
\section{Covariance and Correlation Extras}
The covariance relationship between multiple variables can be expressed in a variance-covariance matrix:

\bordermatrix{   ~ & X & Y & Z\cr
                  X & Var(X) & Cov(X,Y) & Cov(X,Z) \cr
                  Y & Cov(Y,X)  & Var(Y) & Cov(Y,Z)  \cr
                  Z & Cov(Z,X)  & Cov(Z,Y)  & Var(Z)}
=
\bordermatrix{   ~ & X & Y & Z\cr
                  X & \Sexpr{variancex} & \Sexpr{covxy} & \Sexpr{covxz} \cr
                  Y & \Sexpr{covxy}  & \Sexpr{variancey} & \Sexpr{covyz}  \cr
                  Z & \Sexpr{covxz}  & \Sexpr{covyz}  & \Sexpr{variancez}
}

The Variance-Covariance Matrix (also referred to as the VCV or simply the Covariance matrix) is a key part of multivariate statistics and methods, including:
\begin{itemize}
  \item Principal Components Analysis (PCA)
  \item Factor Analysis
  \item Hierarchical Clustering
\end{itemize}

Similarly, the correlation matrix expresses all the correlations among variables.

\bordermatrix{   ~ & X & Y & Z\cr
                  X & Corr(X,X) & Corr(X,Y) & Corr(X,Z) \cr
                  Y & Corr(Y,X)  & Corr(Y,Y) & Corr(Y,Z)  \cr
                  Z & Corr(Z,X)  & Corr(Z,Y)  & Corr(Y,Y)}
=
\bordermatrix{   ~ & X & Y & Z\cr
                  X & 1 & \Sexpr{covxy/(stddevx*stddevy)} & \Sexpr{covxz/(stddevx*stddevz)} \cr
                  Y & \Sexpr{covxy/(stddevx*stddevy)}  & 1 & \Sexpr{covyz/(stddevz*stddevy)}  \cr
                  Z & \Sexpr{covxz/(stddevx*stddevz)}  & \Sexpr{covyz/(stddevz*stddevy)}  & 1}

The Correlation Matrix is a key part of multivariate statistics and methods, including:
\begin{itemize}
  \item Canonical Correlation Analysis
  \item Portfolio Analysis and Optimization
\end{itemize}
<<scatmat,fig.cap="Scatterplot Matrix: Multiple scatterplots and correlations can be combined in one visualization ">>=
require(GGally)
ggscatmat(dsn[,obsname])
@

When two variables have very different distributions, two non-parametric methods can assess the association on the ranks of the variables: $\rho$, the Spearman Rank Correlation, and $\tau$, the Kendall Rank Correlation.
\newpage
\section{Simple Linear Regression}

When a linear correlation exists between two variables, we can explore causation using a \textbf{Simple Linear Regression}, also called Ordinary Least Squares (OLS), regressing a dependent variable, denoted $Y$, on an independent variable, denoted $X$ as a line with the form:
\begin{equation*}
Y=\alpha + \hat{\beta}X
\end{equation*}
<<ols,fig.cap="Green regression line with prediction error, as noted in red on the chart",fig.env="marginfigure">>=
beta=covxy/variancex
alpha=hmean[2]-beta*hmean[1]
dsn$mint=alpha+beta*dsn$Assault
scp=ggplot(dsn,aes(y=Murder,x=Assault))+geom_point()+
  scale_x_continuous(name=obstext[1])+
  scale_y_continuous(name=obstext[2])+
 geom_abline(intercept = alpha, slope = beta,colour="green",size=1)+
  geom_linerange(color="red",ymin=dsn$mint,ymax=dsn$Murder,xmin=dsn$Assault,xmax=dsn$Assault)+
  theme(axis.text = element_text(size=1))

print(scp)
@

This is very similar to the traditional algebra formula $y=mx+b$ with slope $m$ and y-intercept $b$. In this case, the slope is $\hat{\beta}$.
\begin{equation*}
\hat{\beta}=\frac{Cov(X,Y)}{Var(X)}=Corr(X,Y)\frac{StdDev(Y)}{StdDev(X)}
\end{equation*}
Note that $\hat{\beta}$ is very close to the correlation value of $\frac{Cov(X,Y)}{StDev(X)StDev(Y)}$, but with $StDev(X)$ replacing $StDev(Y)$, to indicate the dependency of $Y$ upon $X$.

For the US Arrests data set, 
\begin{equation*}
\hat{\beta}=\frac{\Sexpr{covxy}}{\Sexpr{variancex}}=\Sexpr{covxy/variancex}
\end{equation*}

The linear regression always goes through the point $(\bar{x},\bar{y})$, so returning to algebra, any point plus the slope determines the line:
\begin{equation*}
\hat{\alpha}=\bar{y}-\hat{\beta}\bar{x}
\end{equation*}

The predicted value for any $y_i$ is $\hat{y_i}$, and the prediction error is $\hat{\epsilon}=y_i - \hat{y_i}$.

Some properties of the Simple Linear Regression:
\begin{itemize}
  \item $\Sigma_{i=1}^{N} \hat{\epsilon}=0 $
  \item $\Sigma_{i=1}^{N} x_i \hat{\epsilon}=0 $
  \item The predicted values $\hat{y_i}$ minimize the sum of the squared prediction errors, $\Sigma_{i=1}^{N} \hat{\epsilon}^2$, often referred to as Sum Squared Errors, or SSE.
  \item The regression equation is valid to predict $\hat{y}$ values in the range of X, that is, on the interval (min(X),max(X)), and any prediction will be in the range of (min(Y),max(Y))
\end{itemize}



\end{document}
